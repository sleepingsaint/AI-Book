{
    "hasNextPage": true,
    "data": [
        {
            "id": 9054,
            "title": "How to Avoid Overfitting in Deep Learning Neural Networks",
            "url": "https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2018-12-17T00:00:00",
            "description": "Training a deep neural network that can generalize well to new data is a challenging problem. A model with too little capacity cannot learn the problem, whereas a model with too much capacity can learn it too well and overfit the training dataset. Both cases result in a model that does not generalize well. A [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/12/A-Gentle-Introduction-to-Regularization-to-Reduce-Overfitting-and-Improve-Generalization-Error.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 6398,
            "title": "Soft Actor Critic\u2014Deep Reinforcement Learning with Real-World Robots",
            "url": "https://bair.berkeley.edu/blog/2018/12/14/sac/",
            "authors": "Tuomas Haarnoja, Vitchyr Pong, Kristian Hartikainen, Aurick Zhou, Murtaza Dalal, and Sergey Levine",
            "tags": null,
            "publishedOn": "2018-12-14T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/sac/ant.png",
            "sourceId": 4,
            "source": "BAIR Blog"
        },
        {
            "id": 9055,
            "title": "How to Improve Deep Learning Model Robustness by Adding Noise",
            "url": "https://machinelearningmastery.com/how-to-improve-deep-learning-model-robustness-by-adding-noise/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2018-12-14T00:00:00",
            "description": "Adding noise to an underconstrained neural network model with a small training dataset can have a regularizing effect and reduce overfitting. Keras supports the addition of Gaussian noise via a separate layer called the GaussianNoise layer. This layer can be used to add noise to an existing model. In this tutorial, you will discover how [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Train-and-Test-Accuracy-with-Hidden-Layer-Noise.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 9974,
            "title": "How AI Training Scales",
            "url": "https://openai.com/blog/science-of-ai/",
            "authors": null,
            "tags": "Research, Milestones",
            "publishedOn": "2018-12-14T00:00:00",
            "description": "We've discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training.",
            "thumbnail": "https://openai.com/content/images/2018/12/noise-summary-whitebg@2x-1.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 7602,
            "title": "Improving the Effectiveness of Diabetic Retinopathy Models",
            "url": "http://ai.googleblog.com/2018/12/improving-effectiveness-of-diabetic.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2018-12-13T00:01:00-08:00",
            "description": null,
            "thumbnail": "https://4.bp.blogspot.com/-L07yZHJ3_rU/XBHB5tr8aRI/AAAAAAAADoQ/mnOZh8ybI9I6c7aB8wWT4yswPFKOpmSIACLcBGAs/s72-c/image1.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1264,
            "title": "Amazon SageMaker Automatic Model Tuning now supports early stopping of training jobs",
            "url": "https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-automatic-model-tuning-now-supports-early-stopping-of-training-jobs/",
            "authors": "Huibin Shen, Fan Li, Miroslav Miladinovic",
            "tags": "Amazon SageMaker, Artificial Intelligence",
            "publishedOn": "2018-12-13T00:00:00",
            "description": "In June 2018, we launched Amazon SageMaker Automatic Model Tuning, a feature that automatically finds well-performing hyperparameters to train a machine learning model with. Unlike model parameters learned during training, hyperparameters are set before the learning process begins. A typical example of the use of hyperparameters is the learning rate of stochastic gradient procedures. Using [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/12/12/sagemaker-early-stopping-5.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 1948,
            "title": "New Approach to Language Modeling Reduces Speech Recognition Errors by Up to 15%",
            "url": "https://www.amazon.science/blog/new-approach-to-language-modeling-reduces-speech-recognition-errors-by-up-to-15",
            "authors": "Ankur Gandhe",
            "tags": "Conversational AI / Natural-language processing",
            "publishedOn": "2018-12-13T00:00:00",
            "description": "Language models are a key component of automatic speech recognition systems, which convert speech into text. A language model captures the statistical likelihood of any particular string of words, so it can help decide between different interpretations of the same sequence of sounds.",
            "thumbnail": "https://assets.amazon.science/dims4/default/a68ac73/2147483647/strip/true/crop/1234x648+502+0/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fe2%2F80%2F607174a14c798e207705fd81973a%2Fsample-grammar.png._CB459480040_.png",
            "sourceId": 2,
            "source": "Amazon Science Blog"
        },
        {
            "id": 5518,
            "title": "WNS Hackathon Solutions by Top Finishers",
            "url": "https://www.analyticsvidhya.com/blog/2018/12/wns-hackathon-solutions-by-top-finishers/",
            "authors": "Aishwarya Singh",
            "tags": "Analytics Vidhya, Intermediate, Listicle, Machine Learning, Winners Approach",
            "publishedOn": "2018-12-13T00:00:00",
            "description": "This article covers the top three solutions shared by the winners for WNS online hackathon conducted on 14th-16th September.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/WNS-Analytics-Hackathon_1920-x-480px_02_OQPF2Bi-thumbnail-1200x1200-90-e15444527233821.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 6399,
            "title": "Scaling Multi-Agent Reinforcement Learning",
            "url": "https://bair.berkeley.edu/blog/2018/12/12/rllib/",
            "authors": "Eric Liang and Richard Liaw",
            "tags": null,
            "publishedOn": "2018-12-12T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/rllib/img1.png",
            "sourceId": 4,
            "source": "BAIR Blog"
        },
        {
            "id": 9056,
            "title": "Train Neural Networks With Noise to Reduce Overfitting",
            "url": "https://machinelearningmastery.com/train-neural-networks-with-noise-to-reduce-overfitting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2018-12-12T00:00:00",
            "description": "Training a neural network with a small dataset can cause the network to memorize all training examples, in turn leading to overfitting and poor performance on a holdout dataset. Small datasets may also represent a harder mapping problem for neural networks to learn, given the patchy or sparse sampling of points in the high-dimensional input [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/12/Train-Neural-Networks-With-Noise-to-Reduce-Overfitting.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13854,
            "title": "Massively Parallel  Hyperparameter Optimization",
            "url": "https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/",
            "authors": null,
            "tags": "Automl, Machine learning, Research",
            "publishedOn": "2018-12-12T00:00:00",
            "description": "Machine learning algorithms typically have configuration parameters, or hyperparameters, that influence their output and ultimately predictive accuracy (Melis et al., 2018).  Some common examples of hyperparameters include learning rate, dropout, and activation function for neural networks, maximum",
            "thumbnail": "https://blog.ml.cmu.edu/wp-content/uploads/2018/12/heatmap.001-min.jpeg",
            "sourceId": 21,
            "source": "ML@CMU Blog"
        },
        {
            "id": 13855,
            "title": "Introducing the ML@CMU Blog",
            "url": "https://blog.ml.cmu.edu/2018/12/12/introducing-the-mlcmu-blog/",
            "authors": null,
            "tags": "Educational, Machine learning, Research",
            "publishedOn": "2018-12-12T00:00:00",
            "description": "CMU is a leader in the field of machine learning research, both within the Machine Learning Department (MLD) and across the university in general. Traditional conference and journal publications, along with technical talks, are our primary avenues for disseminating our research. However, given the i",
            "thumbnail": "https://blog.ml.cmu.edu/wp-content/uploads/2018/11/cover-introduction-mlblog-2-970x323.jpg",
            "sourceId": 21,
            "source": "ML@CMU Blog"
        },
        {
            "id": 7603,
            "title": "Grasp2Vec: Learning Object Representations from Self-Supervised Grasping",
            "url": "http://ai.googleblog.com/2018/12/grasp2vec-learning-object.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2018-12-11T13:21:00-08:00",
            "description": null,
            "thumbnail": "https://2.bp.blogspot.com/-x49Icv-jXq8/XBACgxvnQ3I/AAAAAAAADm4/ozeCSxL2blcoQ0TcocH3dEckk5CyxlJ2ACLcBGAs/s72-c/image8.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1949,
            "title": "Distributed \u201cRe-Ranker\u201d Ensures That Alexa Improvements Reach Customers ASAP",
            "url": "https://www.amazon.science/blog/distributed-re-ranker-ensures-that-alexa-improvements-reach-customers-asap",
            "authors": "Chengwei Su",
            "tags": "Conversational AI / Natural-language processing",
            "publishedOn": "2018-12-11T00:00:00",
            "description": "Suppose that you say to Alexa, \u201cAlexa, play Mary Poppins.\u201d Alexa must decide whether you mean the book, the video, or the soundtrack. How should she do it?",
            "thumbnail": "https://assets.amazon.science/dims4/default/590b1d5/2147483647/strip/true/crop/1269x666+296+0/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F8e%2F03%2F2f8c9bc743188d5c6972d80b8ebb%2Fsemantic-error-rate-example.png._CB461160527_.png",
            "sourceId": 2,
            "source": "Amazon Science Blog"
        },
        {
            "id": 7604,
            "title": "Providing Gender-Specific Translations in Google Translate",
            "url": "http://ai.googleblog.com/2018/12/providing-gender-specific-translations.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2018-12-10T14:30:00-08:00",
            "description": null,
            "thumbnail": "https://2.bp.blogspot.com/-iyYEaRWBp-Y/XA7kJAl-OZI/AAAAAAAADmc/_kb9Qft8CLkmMN1PAaHLMtuGejCRaYq1wCLcBGAs/s72-c/image3.jpg",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 5519,
            "title": "Building a Face Detection Model from Video using Deep Learning (Python Implementation)",
            "url": "https://www.analyticsvidhya.com/blog/2018/12/introduction-face-detection-video-deep-learning-python/",
            "authors": "JalFaizy Shaikh",
            "tags": "Advanced, Computer Vision, Deep Learning, Image, Object Detection, Python, Supervised, Technique, Unstructured Data",
            "publishedOn": "2018-12-10T00:00:00",
            "description": "Face detection is all the rage these days - but can you build a model on a video? Things get tricky when the subject is dynamic - learn all about it here!",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Face_detection.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 7006,
            "title": "Named entity recognition with Bert",
            "url": "https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/",
            "authors": null,
            "tags": "Named entity recognition, Nlp, Deep learning",
            "publishedOn": "2018-12-10T00:00:00",
            "description": "In 2018 we saw the rise of pretraining and finetuning in natural language processing. Large neural networks have been trained on general tasks like language modeling and then fine-tuned for classification tasks. One of the latest milestones in this development is the release of BERT.",
            "thumbnail": "https://www.depends-on-the-definition.com/images/named-entity-recognition-with-bert_files/bert-input-output.png",
            "sourceId": 7,
            "source": "Depends On The Definition Blog"
        },
        {
            "id": 9057,
            "title": "Use Early Stopping to Halt the Training of Neural Networks At the Right Time",
            "url": "https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2018-12-10T00:00:00",
            "description": "A problem with training neural networks is in the choice of the number of training epochs to use. Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plots-of-Loss-on-Train-and-Test-Datasets-While-Training-Showing-an-Overfit-Model.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7605,
            "title": "Adding Diversity to Images with Open Images Extended",
            "url": "http://ai.googleblog.com/2018/12/adding-diversity-to-images-with-open.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2018-12-07T06:00:00-08:00",
            "description": null,
            "thumbnail": "https://1.bp.blogspot.com/-BCe-QSVHchQ/XAp4l-gKxuI/AAAAAAAADmQ/xbN5m2feef4gJjTVenOqapQ8zPpVbSxuACLcBGAs/s72-c/Screen%2BShot%2B2018-12-06%2Bat%2B5.14.00%2BPM.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1950,
            "title": "The role of context in redefining human-computer interaction",
            "url": "https://www.amazon.science/blog/the-role-of-context-in-redefining-human-computer-interaction",
            "authors": "Ruhi Sarikaya",
            "tags": "Conversational AI / Natural-language processing",
            "publishedOn": "2018-12-07T00:00:00",
            "description": "In the past few years, advances in artificial intelligence have captured our imaginations and led to the widespread use of voice services on our phones and in our homes. ",
            "thumbnail": "https://assets.amazon.science/dims4/default/26129e4/2147483647/strip/true/crop/1920x1008+0+36/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F57%2F64%2F16e4443b444eb381a0f08e5cdc63%2Fnatural-skill-interaction.png._CB480964660_.png",
            "sourceId": 2,
            "source": "Amazon Science Blog"
        },
        {
            "id": 9058,
            "title": "A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks",
            "url": "https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2018-12-07T00:00:00",
            "description": "A major challenge in training neural networks is how long to train them. Too little training will mean that the model will underfit the train and the test sets. Too much training will mean that the model will overfit the training dataset and have poor performance on the test set. A compromise is to train [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/12/A-Gentle-Introduction-to-Early-Stopping-for-Avoiding-Overtraining-Neural-Network-Models.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 1265,
            "title": "Build a serverless Twitter reader using AWS Fargate",
            "url": "https://aws.amazon.com/blogs/machine-learning/build-a-serverless-twitter-reader-using-aws-fargate/",
            "authors": "Raja Mani, Luis Pineda",
            "tags": "AWS Fargate, Compute",
            "publishedOn": "2018-12-06T00:00:00",
            "description": "In a previous post, Ben Snively and Viral Desai showed us how to build a social media dashboard using serverless technology. The social media dashboard reads tweets with the #AWS hashtag, uses machine learning based services to do translation, and natural language processing (NLP) to determine topics, entities, and sentiment analysis. Finally, it aggregates this [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/12/05/twitter-fargate-2.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 5520,
            "title": "A Practical Guide to Object Detection using the Popular YOLO Framework \u2013 Part III (with Python codes)",
            "url": "https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/",
            "authors": "Pulkit Sharma",
            "tags": "Advanced, Algorithm, Computer Vision, Deep Learning, Image, Object Detection, Python, Supervised, Technique, Unstructured Data",
            "publishedOn": "2018-12-06T00:00:00",
            "description": "A practical guide to yolo framework and how yolo framework function. Learn about object detection using yolo framework and implementation of yolo in python.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-29-13-03-17.png",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 6892,
            "title": "AlphaZero: Shedding new light on chess, shogi, and Go",
            "url": "https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go",
            "authors": null,
            "tags": "Blog",
            "publishedOn": "2018-12-06T00:00:00",
            "description": "In late 2017 we introduced AlphaZero, a single system that taught itself from scratch how to master the games of chess, shogi (Japanese chess), and Go, beating a world-champion program in each case. We were excited by the preliminary results and thrilled to see the response from members of the chess community, who saw in AlphaZero\u2019s games a ground-breaking, highly dynamic and \u201cunconventional\u201d style of play that differed from any chess playing engine that came before it.",
            "thumbnail": "https://assets-global.website-files.com/621e749a546b7592125f38ed/6233ab99e961d9133104ecd4_alphazero.jpg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        },
        {
            "id": 9975,
            "title": "Quantifying Generalization in Reinforcement Learning",
            "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning/",
            "authors": null,
            "tags": "Research",
            "publishedOn": "2018-12-06T00:00:00",
            "description": "We\u2019re releasing a new training environment, CoinRun, that precisely quantifies an agent\u2019s ability to transfer its experience to novel test environments.",
            "thumbnail": "https://openai.com/content/images/2018/12/Screen-Shot-2018-12-06-at-8.13.05-AM-2.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 13451,
            "title": "Tools for generating deep neural networks with efficient network architectures",
            "url": "https://www.oreilly.com/radar/podcast/tools-for-generating-deep-neural-networks-with-efficient-network-architectures/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2018-12-06T00:00:00",
            "description": "The O\u2019Reilly Data Show Podcast: Alex Wong on building human-in-the-loop automation solutions for enterprise machine learning.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/photosynthesis-391447_1920_crop-90eefd0e8285acad8952e79316ff00d8-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 7606,
            "title": "TF-Ranking: A Scalable TensorFlow Library for Learning-to-Rank",
            "url": "http://ai.googleblog.com/2018/12/tf-ranking-scalable-tensorflow-library.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2018-12-05T10:00:00-08:00",
            "description": null,
            "thumbnail": "https://3.bp.blogspot.com/-OKX1y8NRMHg/XAcD4ZpM1xI/AAAAAAAADl8/Putab3G-V2II18eW2t9f42BYErnvFpztwCLcBGAs/s72-c/image1.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1266,
            "title": "Anomaly detection on Amazon DynamoDB Streams using the Amazon SageMaker Random Cut Forest algorithm",
            "url": "https://aws.amazon.com/blogs/machine-learning/anomaly-detection-on-amazon-dynamodb-streams-using-the-amazon-sagemaker-random-cut-forest-algorithm/",
            "authors": "YongSeong Lee",
            "tags": "Amazon DynamoDB, Amazon SageMaker, Artificial Intelligence",
            "publishedOn": "2018-12-05T00:00:00",
            "description": "Have you considered introducing anomaly detection technology to your business? Anomaly detection is a technique used to identify rare items, events, or observations which raise suspicion by differing significantly from the majority of the data you are analyzing.\u00a0 The applications of anomaly detection are wide-ranging including the detection of abnormal purchases or cyber intrusions in [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/11/30/anomaly-detection-sagemaker-1.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 1267,
            "title": "Announcing the Winners of the 2018 AWS AI Hackathon",
            "url": "https://aws.amazon.com/blogs/machine-learning/announcing-the-winners-of-the-2018-aws-ai-hackathon/",
            "authors": "Cameron Peron",
            "tags": "Artificial Intelligence",
            "publishedOn": "2018-12-05T00:00:00",
            "description": "We\u2019re excited to announce the winners of the 2018 AWS AI Hackathon.\u00a0 Horacio Canales has won first place with his \u201cSecond Alert\u201d project. This project enables users from around the world to identify missing persons, including human trafficking victims, children too young to remember their family members\u2019 names, and mentally handicapped individuals. Horacio built the [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/12/05/ai-hackathon-1.jpg",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 6400,
            "title": "Building Gene Expression Atlases with Deep Generative Models for Single-cell Transcriptomics",
            "url": "https://bair.berkeley.edu/blog/2018/12/05/genes/",
            "authors": "Romain Lopez and Chenling Xu",
            "tags": null,
            "publishedOn": "2018-12-05T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/genes/scvi.jpg",
            "sourceId": 4,
            "source": "BAIR Blog"
        }
    ]
}