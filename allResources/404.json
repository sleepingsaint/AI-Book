{
    "hasNextPage": true,
    "data": [
        {
            "id": 9227,
            "title": "Gentle Introduction to Statistical Language Modeling and Neural Language Models",
            "url": "https://machinelearningmastery.com/statistical-language-modeling-and-neural-language-models/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-11-01T00:00:00",
            "description": "Language modeling is central to many important natural language processing tasks. Recently, neural-network-based language models have demonstrated better performance than classical methods both standalone and as part of more challenging natural language processing tasks. In this post, you will discover language modeling for natural language processing. After reading this post, you will know: Why language [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/11/Gentle-Introduction-to-Statistical-Language-Modeling-and-Neural-Language-Models.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7719,
            "title": "Eager Execution: An imperative, define-by-run interface to TensorFlow",
            "url": "http://ai.googleblog.com/2017/10/eager-execution-imperative-define-by.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-31T10:30:00-07:00",
            "description": null,
            "thumbnail": "https://research.google/static/images/blog/google-ai-meta.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 9228,
            "title": "Gentle Introduction to Global Attention for Encoder-Decoder Recurrent Neural Networks",
            "url": "https://machinelearningmastery.com/global-attention-for-encoder-decoder-recurrent-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-10-31T00:00:00",
            "description": "The encoder-decoder model provides a pattern for using recurrent neural networks to address challenging sequence-to-sequence prediction problems such as machine translation. Attention is an extension to the encoder-decoder model that improves the performance of the approach on longer sequences. Global attention is a simplification of attention that may be easier to implement in declarative deep [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/Gentle-Introduction-to-Global-Attention-for-Encoder-Decoder-Recurrent-Neural-Networks.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7720,
            "title": "Closing the Simulation-to-Reality Gap for Deep Robotic Learning",
            "url": "http://ai.googleblog.com/2017/10/closing-simulation-to-reality-gap-for.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-30T21:02:00-07:00",
            "description": null,
            "thumbnail": "https://4.bp.blogspot.com/-_ZVhyv8ZcL4/WfdkC07grzI/AAAAAAAACGo/0eH6prT8jIUCXJz_27QURrk4ig1O6wFpACLcBGAs/s72-c/image4.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 5686,
            "title": "A Comprehensive Tutorial to Learn Data Science with Julia from Scratch",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/comprehensive-tutorial-learn-data-science-julia-from-scratch/",
            "authors": "[email\u00a0protected] Sanad",
            "tags": "Beginner, Classification, Data Exploration, Data Visualization, Julia, Machine Learning, Programming, Structured Data, Supervised",
            "publishedOn": "2017-10-30T00:00:00",
            "description": "A comprehensive tutorial to learn data science with Julia from scratch. In this article learn about data type and building machine learning models in Julia.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/30085609/Julia-Language-Logo.png",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9229,
            "title": "Deep Convolutional Neural Network for Sentiment Analysis (Text Classification)",
            "url": "https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-30T00:00:00",
            "description": "Develop a Deep Learning Model to Automatically Classify Movie Reviews as Positive or Negative in Python with Keras, Step-by-Step. Word embeddings are a technique for representing text where different words with similar meaning have a similar real-valued vector representation. They are a key breakthrough that has led to great performance of neural network models on [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Develop-a-Word-Embedding-Model-for-Predicting-Movie-Review-Sentiment.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 9230,
            "title": "How to Use the Keras Functional API for Deep Learning",
            "url": "https://machinelearningmastery.com/keras-functional-api-deep-learning/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning",
            "publishedOn": "2017-10-27T00:00:00",
            "description": "The Keras Python library makes creating deep learning models fast and easy. The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs. The functional API in Keras is an alternate way [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/08/multiple_inputs.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 5687,
            "title": "The Essential NLP Guide for data scientists (with codes for top 10 common NLP tasks)",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/essential-nlp-guide-data-scientists-top-10-nlp-tasks/",
            "authors": "NSS",
            "tags": "Deep Learning, Intermediate, Listicle, NLP, Python, Technique",
            "publishedOn": "2017-10-26T00:00:00",
            "description": "The essential guide to NLP. This article provides resources and codes for 10 most common nlp tasks including stemming, lemmatization, Word Embeddings etc.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/26015527/121.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 6426,
            "title": "DART: Noise Injection for Robust Imitation Learning",
            "url": "https://bair.berkeley.edu/blog/2017/10/26/dart/",
            "authors": "Michael Laskey, Jonathan Lee, and Ken Goldberg",
            "tags": null,
            "publishedOn": "2017-10-26T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/dart/dart_intuition.png",
            "sourceId": 4,
            "source": "BAIR Blog"
        },
        {
            "id": 9231,
            "title": "How to Develop a Seq2Seq Model for Neural Machine Translation in Keras",
            "url": "https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-26T00:00:00",
            "description": "The encoder-decoder model provides a pattern for using recurrent neural networks to address challenging sequence-to-sequence prediction problems, such as machine translation. Encoder-decoder models can be developed in the Keras Python deep learning library and an example of a neural machine translation system developed with this model has been described on the Keras blog, with sample [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Define-an-Encoder-Decoder-Sequence-to-Sequence-Model-for-Neural-Machine-Translation-in-Keras.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 10012,
            "title": "Learning a Hierarchy",
            "url": "https://openai.com/blog/learning-a-hierarchy/",
            "authors": null,
            "tags": "Research",
            "publishedOn": "2017-10-26T00:00:00",
            "description": "We've developed a hierarchical reinforcement learning algorithm that learns\nhigh-level actions useful for solving a range of tasks, allowing fast solving of\ntasks requiring thousands of timesteps. Our algorithm, when applied to a set of\nnavigation problems, discovers a set of high-level actions for walking and\ncrawling in different directions,",
            "thumbnail": "https://openai.com/content/images/2017/10/mlsh_hierarchy.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 13568,
            "title": "Machine intelligence for content distribution, logistics, smarter cities, and more",
            "url": "https://www.oreilly.com/radar/podcast/machine-intelligence-for-content-distribution-logistics-smarter-cities-and-more/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2017-10-26T00:00:00",
            "description": "The O\u2019Reilly Data Show Podcast: Rhea Liu on technology trends in China.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/6166346625_9b2984a465_o_crop-226b043b7ab614929b1766d6faf0971f-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 1508,
            "title": "Announcing New AWS Deep Learning AMI for Amazon EC2 P3 Instances",
            "url": "https://aws.amazon.com/blogs/machine-learning/announcing-new-aws-deep-learning-ami-for-amazon-ec2-p3-instances/",
            "authors": "Cynthya Peranandam",
            "tags": "AWS Deep Learning AMIs",
            "publishedOn": "2017-10-25T00:00:00",
            "description": "We\u2019re pleased to announce a new set of AWS Deep Learning AMIs, which come pre-installed with deep learning frameworks optimized for the NVIDIA Volta V100 GPUs in the new Amazon EC2 P3 instance family. The new P3 instances are perfect for deep learning, with eight NVIDIA Volta GPUs available in a single p3.16xlarge instance, which [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/11/21/Social_Graphics_1.png",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 1509,
            "title": "Research Spotlight:\u00a0BMXNet \u2013 An Open Source Binary Neural Network Implementation Based On MXNet",
            "url": "https://aws.amazon.com/blogs/machine-learning/research-spotlight-bmxnet-an-open-source-binary-neural-network-implementation-based-on-mxnet/",
            "authors": "Haojin Yang, Christian Bartz, Martin Fritzsche, Christoph Meinel",
            "tags": "Apache MXNet on AWS",
            "publishedOn": "2017-10-25T00:00:00",
            "description": "This is guest post by Haojin Yang, Martin Fritzsche, Christian Bartz, Christoph Meinel from the Hasso-Plattner-Institut, Potsdam Germany.\u00a0We are excited to see research drive practical implementation of deep learning on low power devices. This work plays an important part in expanding powerful intelligent capabilities into our everyday lives. In recent years, deep learning technologies have [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/25/bmxnet-5.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 9232,
            "title": "How to Index, Slice and Reshape NumPy Arrays for Machine Learning",
            "url": "https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/",
            "authors": "Jason Brownlee",
            "tags": "Linear Algebra",
            "publishedOn": "2017-10-25T00:00:00",
            "description": "Machine learning data is represented as arrays. In Python, data is almost universally represented as NumPy arrays. If you are new to Python, you may be confused by some of the pythonic ways of accessing data, such as negative indexing and array slicing. In this tutorial, you will discover how to manipulate and access your [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Index-Slice-and-Reshape-NumPy-Arrays-for-Machine-Learning-in-Python.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 9233,
            "title": "Difference Between Return Sequences and Return States for LSTMs in Keras",
            "url": "https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-10-24T00:00:00",
            "description": "The Keras deep learning library provides an implementation of the Long Short-Term Memory, or LSTM, recurrent neural network. As part of this implementation, the Keras API provides access to both return sequences and return state. The use and difference between these data can be confusing when designing sophisticated recurrent neural network models, such as the [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/Understand-the-Difference-Between-Return-Sequences-and-Return-States-for-LSTMs-in-Keras.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13569,
            "title": "How companies can navigate the age of machine learning",
            "url": "https://www.oreilly.com/radar/how-companies-can-navigate-the-age-of-machine-learning/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2017-10-24T00:00:00",
            "description": "To become a \u201cmachine learning company,\u201d you need tools and processes to overcome challenges in data, engineering, and models.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/guillaume_brouscon_compass_card_hm_46_portolan_atlas_and_nautical_almanac_france_1543_crop-9b13b40d979d0d1b856744b6ac7a4433-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 7721,
            "title": "Announcing OpenFermion: The Open Source Chemistry Package for Quantum Computers",
            "url": "http://ai.googleblog.com/2017/10/announcing-openfermion-open-source.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-23T10:09:00-07:00",
            "description": null,
            "thumbnail": "https://research.google/static/images/blog/google-ai-meta.png",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1510,
            "title": "Build an Autonomous Vehicle Part 2: Driving Your Vehicle",
            "url": "https://aws.amazon.com/blogs/machine-learning/build-an-autonomous-vehicle-part-2-driving-your-vehicle/",
            "authors": "Justin De Castri, Keji Xu",
            "tags": "AWS re:Invent",
            "publishedOn": "2017-10-23T00:00:00",
            "description": "This is the second blog post in our series that teaches you how to build a 1/16th scale autonomous car. You can also tune in to our Twitch streams to review concepts discussed in these blogs. After following along with us, you can bring your own car to race at the re:Invent Robocar Rally 2017, [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/23/robocar-2-2.jpg",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 9234,
            "title": "Best Practices for Text Classification with Deep Learning",
            "url": "https://machinelearningmastery.com/best-practices-document-classification-deep-learning/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-23T00:00:00",
            "description": "Text classification describes a general class of problems such as predicting the sentiment of tweets and movie reviews, as well as classifying email as spam or not. Deep learning methods are proving very good at text classification, achieving state-of-the-art results on a suite of standard academic benchmark problems. In this post, you will discover some [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/Best-Practices-for-Document-Classification-with-Deep-Learning.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7022,
            "title": "Guide to sequence tagging with neural networks",
            "url": "https://www.depends-on-the-definition.com/guide-sequence-tagging-neural-networks-python/",
            "authors": null,
            "tags": "Named entity recognition, Nlp, Deep learning",
            "publishedOn": "2017-10-22T00:00:00",
            "description": "This is the third post in my series about named entity recognition. If you haven\u2019t seen the last two, have a look now. The last time we used a conditional random field to model the sequence structure of our sentences.",
            "thumbnail": "https://www.depends-on-the-definition.com/images/mstile-150x150.png",
            "sourceId": 7,
            "source": "Depends On The Definition Blog"
        },
        {
            "id": 1511,
            "title": "How Astro Built Astrobot Voice, a Chatbot for Email",
            "url": "https://aws.amazon.com/blogs/machine-learning/how-astro-built-astrobot-voice-a-chatbot-for-email/",
            "authors": "Roland Schemers",
            "tags": "Amazon Lex",
            "publishedOn": "2017-10-20T00:00:00",
            "description": "This is a guest post by Roland Schemers, CTO of Astro Technology, Inc. Astro, in\u00a0their own words, \u201ccreates modern email apps for Mac, iOS and Android, powered by artificial intelligence, built for people and teams. With Astrobot Voice, an in-app email voice assistant, you can now read, manage, and reply to emails without leaving Astro\u2019s [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/18/astron-inc-2-678x630.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 9235,
            "title": "How to Develop a Deep Learning Bag-of-Words Model for Sentiment Analysis (Text Classification)",
            "url": "https://machinelearningmastery.com/deep-learning-bag-of-words-model-sentiment-analysis/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-20T00:00:00",
            "description": "Movie reviews can be classified as either favorable or not. The evaluation of movie review text is a classification problem often called sentiment analysis. A popular technique for developing sentiment analysis models is to use a bag-of-words model that transforms documents into vectors where each word in the document is assigned a score. In this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Develop-a-Deep-Learning-Bag-of-Words-Model-for-Predicting-Sentiment-in-Movie-Reviews.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7722,
            "title": "Announcing AVA: A Finely Labeled Video Dataset for Human Action Understanding",
            "url": "http://ai.googleblog.com/2017/10/announcing-ava-finely-labeled-video.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-19T11:42:00-07:00",
            "description": null,
            "thumbnail": "https://4.bp.blogspot.com/-F2rLgrB1t_s/Wee8Le1RF2I/AAAAAAAACGI/dWdfaRbROvcmvsE1X6zEfxd4qNDAlGaBACLcBGAs/s72-c/image1.gif",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1512,
            "title": "Convert Your Text into an MP3 File with Amazon Polly and a Simple Python Script",
            "url": "https://aws.amazon.com/blogs/machine-learning/convert-your-text-into-an-mp3-file-with-amazon-polly-and-a-simple-python-script/",
            "authors": "Dzidas Martinaitis",
            "tags": "Amazon Polly",
            "publishedOn": "2017-10-19T00:00:00",
            "description": "Text-to-speech technology can turn any digital text into a multimedia experience, so people can listen to news, blog articles, or even a PDF document, while multitasking or on-the-go. With Amazon Polly, you can convert your RSS feed or email, and store the synthesized speech in the form of audio files. Currently, the Amazon Polly console [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/11/24/polly-social.jpg",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 9236,
            "title": "Implementation Patterns for the Encoder-Decoder RNN Architecture with Attention",
            "url": "https://machinelearningmastery.com/implementation-patterns-encoder-decoder-rnn-architecture-attention/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-10-19T00:00:00",
            "description": "The encoder-decoder architecture for recurrent neural networks is proving to be powerful on a host of sequence-to-sequence prediction problems in the field of natural language processing. Attention is a mechanism that addresses a limitation of the encoder-decoder architecture on long sequences, and that in general speeds up the learning and lifts the skill of the [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/Implementation-Patterns-for-the-Encoder-Decoder-RNN-Architecture-with-Attention.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 10013,
            "title": "Generalizing from Simulation",
            "url": "https://openai.com/blog/generalizing-from-simulation/",
            "authors": null,
            "tags": "Research",
            "publishedOn": "2017-10-19T00:00:00",
            "description": "Our latest robotics techniques allow robot controllers, trained entirely in\nsimulation and deployed on physical robots, to react to unplanned changes in the\nenvironment as they solve simple tasks. That is, we've used these techniques to\nbuild closed-loop\n[https://en.wikipedia.org/wiki/Control_theory#Classical_control_theory] systems\nrather",
            "thumbnail": "https://openai.com/content/images/2017/10/test046.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 1513,
            "title": "AWS Deep Learning AMI Now Supports PyTorch, Keras 2 and Latest Deep Learning Frameworks",
            "url": "https://aws.amazon.com/blogs/machine-learning/aws-deep-learning-ami-now-supports-pytorch-keras-2-and-latest-deep-learning-frameworks/",
            "authors": "Cynthya Peranandam",
            "tags": "Artificial Intelligence, AWS Deep Learning AMIs",
            "publishedOn": "2017-10-18T00:00:00",
            "description": "Today, we\u2019re pleased to announce an update to the AWS Deep Learning AMI. The AWS Deep Learning AMI, which lets you spin up a complete deep learning environment on AWS in a single click, now includes PyTorch, Keras 1.2 and 2.0 support, along with popular machine learning frameworks such as TensorFlow, Caffe2 and Apache MXNet. [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/11/21/Social_Graphics_1.png",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 6934,
            "title": "AlphaGo Zero: Starting from scratch",
            "url": "https://www.deepmind.com/blog/alphago-zero-starting-from-scratch",
            "authors": null,
            "tags": "Blog",
            "publishedOn": "2017-10-18T00:00:00",
            "description": "Artificial intelligence research has made rapid progress in a wide variety of domains from speech recognition and image classification to genomics and drug discovery. In many cases, these are specialist systems that leverage enormous amounts of human expertise and data.",
            "thumbnail": "https://assets-global.website-files.com/621e749a546b7592125f38ed/62266f9efe434cec045e45cf_AlphaGoZero.jpg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        },
        {
            "id": 9237,
            "title": "How to Clean Text for Machine Learning with Python",
            "url": "https://machinelearningmastery.com/clean-text-machine-learning-python/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-18T00:00:00",
            "description": "You cannot go straight from raw text to fitting a machine learning or deep learning model. You must clean your text first, which means splitting it into words and handling punctuation and case. In fact, there is a whole suite of text preparation methods that you may need to use, and the choice of methods [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/11/How-to-Develop-Multilayer-Perceptron-Models-for-Time-Series-Forecasting.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        }
    ]
}