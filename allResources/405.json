{
    "hasNextPage": true,
    "data": [
        {
            "id": 7723,
            "title": "Portrait mode on the Pixel 2 and Pixel 2 XL smartphones",
            "url": "http://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-17T11:41:00-07:00",
            "description": null,
            "thumbnail": "https://4.bp.blogspot.com/-pQ1j2lyMvMw/WeUbl8BfPdI/AAAAAAAACDk/_nR4-zLdzIoaxOHhbb3AHPRSQRwhb8FfQCLcBGAs/s72-c/girl-with-the-orange-hat-s.jpg",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1514,
            "title": "Your Guide to Machine Learning at re:Invent 2017",
            "url": "https://aws.amazon.com/blogs/machine-learning/your-guide-to-machine-learning-at-reinvent-2017/",
            "authors": "Cynthya Peranandam",
            "tags": "AWS re:Invent",
            "publishedOn": "2017-10-17T00:00:00",
            "description": "re:Invent 2017 is almost here! As you plan your agenda, machine learning is undoubtedly a hot topic on your list. This year we have a lot of great technical content in the Machine Learning track, with over 50 breakout sessions, hands-on workshops, labs, and deep-dive chalk talks. You\u2019ll hear first-hand from customers and partners about [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/13/reinvent2017.jpg",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 6427,
            "title": "Learning Long Duration Sequential Task Structure From Demonstrations with Application in Surgical Robotics",
            "url": "https://bair.berkeley.edu/blog/2017/10/17/lfd-surgical-robots/",
            "authors": "Sanjay Krishnan, Roy Fox, and Ken Goldberg",
            "tags": null,
            "publishedOn": "2017-10-17T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/surgical_robots/tensioning-task.png",
            "sourceId": 4,
            "source": "BAIR Blog"
        },
        {
            "id": 7088,
            "title": "Clojure Numerics, Part 5 - Orthogonalization and Least Squares",
            "url": "https://dragan.rocks/articles/17/Clojure-Numerics-5-Orthogonalization-and-Least-Squares",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-17T00:00:00",
            "description": "How to solve linear systems that have many solutions, or those that have no solutions at all? That's the theme for a thick math textbook, of course, but from...",
            "thumbnail": "http://aiprobook.com/img/dlfp-cover.png",
            "sourceId": 8,
            "source": "Dragan.rocks Blog"
        },
        {
            "id": 9238,
            "title": "How to Develop an Encoder-Decoder Model with Attention in Keras",
            "url": "https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-10-17T00:00:00",
            "description": "The encoder-decoder architecture for recurrent neural networks is proving to be powerful on a host of sequence-to-sequence prediction problems in the field of natural language processing such as machine translation and caption generation. Attention is a mechanism that addresses a limitation of the encoder-decoder architecture on long sequences, and that in general speeds up the [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Develop-an-Encoder-Decoder-Model-with-Attention-for-Sequence-to-Sequence-Prediction-in-Keras.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13570,
            "title": "Planning for AI",
            "url": "https://www.oreilly.com/radar/planning-for-ai/",
            "authors": "Mike Loukides",
            "tags": null,
            "publishedOn": "2017-10-17T00:00:00",
            "description": "What you need know before committing to AI.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/winding-road-1439313435lin_crop-8ee58555ca0d018fe7ad1eec2d279e5a-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 9239,
            "title": "How to Prepare Movie Review Data for Sentiment Analysis (Text Classification)",
            "url": "https://machinelearningmastery.com/prepare-movie-review-data-sentiment-analysis/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-16T00:00:00",
            "description": "Text data preparation is different for each problem. Preparation starts with simple steps, like loading data, but quickly gets difficult with cleaning tasks that are very specific to the data you are working with. You need help as to where to begin and what order to work through the steps from raw data to data [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Prepare-Movie-Review-Data-for-Sentiment-Analysis.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 9240,
            "title": "How Does Attention Work in Encoder-Decoder Recurrent Neural Networks",
            "url": "https://machinelearningmastery.com/how-does-attention-work-in-encoder-decoder-recurrent-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-13T00:00:00",
            "description": "Attention is a mechanism that was developed to improve the performance of the Encoder-Decoder RNN on machine translation. In this tutorial, you will discover the attention mechanism for the Encoder-Decoder model. After completing this tutorial, you will know: About the Encoder-Decoder model and attention mechanism for machine translation. How to implement the attention mechanism step-by-step. [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Feeding-Hidden-State-as-Input-to-Decoder.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 1515,
            "title": "Amazon Polly Expands to the Asia Pacific (Tokyo) Region and Adds Two New Voices",
            "url": "https://aws.amazon.com/blogs/machine-learning/amazon-polly-expands-to-the-asia-pacific-tokyo-region-and-adds-two-new-voices/",
            "authors": "Robin Dautricourt",
            "tags": "Amazon Polly",
            "publishedOn": "2017-10-12T00:00:00",
            "description": "Amazon Polly is an AWS service that turns text into lifelike speech. Today, we are excited to announce the expansion to the Asia Pacific (Tokyo) Region, as well as the release of two new Text-to-Speech voices. We are pleased to present Takumi, a new Japanese male voice, and Matthew, a new US English male voice. [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/11/24/polly-social.jpg",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 1516,
            "title": "Introducing Gluon \u2014 An Easy-to-Use Programming Interface for Flexible Deep Learning",
            "url": "https://aws.amazon.com/blogs/machine-learning/introducing-gluon-an-easy-to-use-programming-interface-for-flexible-deep-learning/",
            "authors": "Vikram Madan",
            "tags": "Apache MXNet on AWS",
            "publishedOn": "2017-10-12T00:00:00",
            "description": "Today, AWS and\u00a0Microsoft announced\u00a0a new specification\u00a0that focuses on improving the speed, flexibility, and accessibility of machine learning technology for all developers, regardless of their deep learning\u00a0framework of choice. The first result of this collaboration is the new Gluon interface, an open source library in Apache MXNet that allows developers of all skill levels to prototype, [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/06/intro-gluon-1.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 13571,
            "title": "Vehicle-to-vehicle communication networks can help fuel smart cities",
            "url": "https://www.oreilly.com/radar/podcast/vehicle-to-vehicle-communication-networks-can-help-fuel-smart-cities/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2017-10-12T00:00:00",
            "description": "The O\u2019Reilly Data Show Podcast: Bruno Fernandez-Ruiz on the importance of building the ground control center of the future.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/5704132134_73f9b3365e_o_crop-636ed60bd9664e033bc759e4397056ae-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 7724,
            "title": "TensorFlow Lattice: Flexibility Empowered by Prior Knowledge",
            "url": "http://ai.googleblog.com/2017/10/tensorflow-lattice-flexibility.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-11T10:00:00-07:00",
            "description": null,
            "thumbnail": "https://i.ytimg.com/vi/kaPheQxIsPY/0.jpg",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 9241,
            "title": "What Are Word Embeddings for Text?",
            "url": "https://machinelearningmastery.com/what-are-word-embeddings/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-11T00:00:00",
            "description": "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems. In this post, you will discover the [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/What-Are-Word-Embeddings-for-Text.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 10014,
            "title": "Meta-Learning for Wrestling",
            "url": "https://openai.com/blog/meta-learning-for-wrestling/",
            "authors": null,
            "tags": "Research",
            "publishedOn": "2017-10-11T00:00:00",
            "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
            "thumbnail": "https://openai.com/content/images/2022/05/twitter-1.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 10015,
            "title": "Competitive Self-Play",
            "url": "https://openai.com/blog/competitive-self-play/",
            "authors": null,
            "tags": "Research, Milestones",
            "publishedOn": "2017-10-11T00:00:00",
            "description": "We've found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind.",
            "thumbnail": "https://openai.com/content/images/2022/05/twitter-1.png",
            "sourceId": 17,
            "source": "OpenAI Blog"
        },
        {
            "id": 5688,
            "title": "Introductory guide to Linear Optimization in Python (with TED videos case study)",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/linear-optimization-in-python/",
            "authors": "guest_blog",
            "tags": "Business Analytics, Intermediate, Machine Learning, Python, Research & Technology, Structured Data, Technique",
            "publishedOn": "2017-10-09T00:00:00",
            "description": "An introduction to linear optimization and example of utilizing linear optimization techniques in python to create a video watch list of TED videos.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/09074827/pexels-photo-114820.jpeg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9242,
            "title": "A Gentle Introduction to the Bag-of-Words Model",
            "url": "https://machinelearningmastery.com/gentle-introduction-bag-words-model/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-09T00:00:00",
            "description": "The bag-of-words model is a way of representing text data when modeling text with machine learning algorithms. The bag-of-words model is simple to understand and implement and has seen great success in problems such as language modeling and document classification. In this tutorial, you will discover the bag-of-words model for feature extraction in natural language [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/A-Gentle-Introduction-to-the-Bag-of-Words-Model.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 1517,
            "title": "Introducing NNVM Compiler: A New Open End-to-End Compiler for AI Frameworks",
            "url": "https://aws.amazon.com/blogs/machine-learning/introducing-nnvm-compiler-a-new-open-end-to-end-compiler-for-ai-frameworks/",
            "authors": "Mu Li",
            "tags": "Apache MXNet on AWS",
            "publishedOn": "2017-10-06T00:00:00",
            "description": "You can choose among multiple artificial intelligence (AI) frameworks to develop AI algorithms. You also have a choice of a wide range of hardware to train and deploy AI models. The diversity of frameworks and hardware is crucial to maintaining the health of the AI ecosystem. This diversity, however, also introduces several challenges to AI [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/11/21/Social_Graphics_1.png",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 6428,
            "title": "Learning Diverse Skills via Maximum Entropy Deep Reinforcement Learning",
            "url": "https://bair.berkeley.edu/blog/2017/10/06/soft-q-learning/",
            "authors": "Haoran Tang and Tuomas Haarnoja",
            "tags": null,
            "publishedOn": "2017-10-06T00:00:00",
            "description": "The BAIR Blog",
            "thumbnail": "http://bair.berkeley.edu/blog/assets/softq/figure_3b_multimodal_policy.png",
            "sourceId": 4,
            "source": "BAIR Blog"
        },
        {
            "id": 6935,
            "title": "Strengthening our commitment to Canadian research",
            "url": "https://www.deepmind.com/blog/strengthening-our-commitment-to-canadian-research",
            "authors": null,
            "tags": "Company",
            "publishedOn": "2017-10-06T00:00:00",
            "description": "Three months ago we announced the opening of DeepMind\u2019s first ever international AI research laboratory in Edmonton, Canada. Today, we are thrilled to announce that we are strengthening our commitment to the Canadian AI community with the opening of a DeepMind office in Montreal, in close collaboration with McGill University.",
            "thumbnail": "https://assets-global.website-files.com/621d30e84caf0be3291dbf1c/621d346e395c98fb65f1185c_brand__symbol_white.svg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        },
        {
            "id": 9243,
            "title": "How to Develop Word Embeddings in Python with Gensim",
            "url": "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-06T00:00:00",
            "description": "Word embeddings are a modern approach for representing text in natural language processing. Word embedding algorithms like word2vec and GloVe are key to the state-of-the-art results achieved by neural network models on natural language processing problems like machine translation. In this tutorial, you will discover how to train and load word embedding models for natural [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Scatter-Plot-of-PCA-Projection-of-Word2Vec-Model.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 1518,
            "title": "Capture and Analyze Customer Demographic Data Using Amazon Rekognition & Amazon Athena",
            "url": "https://aws.amazon.com/blogs/machine-learning/capture-and-analyze-customer-demographic-data-using-amazon-rekognition-amazon-athena/",
            "authors": "Amit Agrawal",
            "tags": "Amazon Athena, Amazon Rekognition, Artificial Intelligence, AWS Lambda",
            "publishedOn": "2017-10-05T00:00:00",
            "description": "Millions of customers shop in brick and mortar stores every day. Currently, most of these retailers have no efficient way to identify these shoppers and understand their purchasing behavior. They rely on third-party market research firms to provide customer demographic and purchase preference information.\r\n\r\nThis blog post walks you how you can use AWS services to identify purchasing behavior of your customers. We show you:\r\n\r\nHow retailers can use captured images in real time.\r\nHow Amazon Rekognition can be used to retrieve face attributes like age range, emotions, gender, etc.\r\nHow you can use Amazon Athena and Amazon QuickSight to analyze the face attributes.\r\nHow you can create unique insights and learn about customer emotions and demographics.\r\nHow to implement serverless architecture using AWS managed services.",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/03/customer-demographic-rekognition-30.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 5689,
            "title": "25 Questions to test a Data Scientist on Image Processing",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/image-skilltest/",
            "authors": "JalFaizy Shaikh",
            "tags": "Computer Vision, Deep Learning, Intermediate, Interview Questions, Machine Learning, Skilltest",
            "publishedOn": "2017-10-05T00:00:00",
            "description": "25 image processing questions to test the skills of data scientists. This article provides multiple choice image processing questions useful in data science",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/05093040/pexels-photo-235767.jpeg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 5690,
            "title": "25 Questions to test a Data Scientist on Support Vector Machines",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/svm-skilltest/",
            "authors": "1201904",
            "tags": "Algorithm, Intermediate, Interview Questions, Machine Learning, Skilltest",
            "publishedOn": "2017-10-05T00:00:00",
            "description": "This article provides 25 questions to test a data scientist on Support Vector Machines, how they work and related concepts in machine learning.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/05093720/fence-wood-fence-wood-limit-48246.jpeg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 6936,
            "title": "WaveNet launches in the Google Assistant",
            "url": "https://www.deepmind.com/blog/wavenet-launches-in-the-google-assistant",
            "authors": null,
            "tags": "Applied",
            "publishedOn": "2017-10-04T00:00:00",
            "description": "Just over a year ago we presented WaveNet, a new deep neural network for generating raw audio waveforms that is capable of producing better and more realistic-sounding speech than existing techniques. At that time, the model was a research prototype and was too computationally intensive to work in consumer products.",
            "thumbnail": "https://assets-global.website-files.com/621d30e84caf0be3291dbf1c/621d346e395c98fb65f1185c_brand__symbol_white.svg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        },
        {
            "id": 7089,
            "title": "Clojure Numerics, Part 4 - Singular Value Decomposition (SVD)",
            "url": "https://dragan.rocks/articles/17/Clojure-Numerics-4-Singular-Value-Decomposition-SVD",
            "authors": null,
            "tags": null,
            "publishedOn": "2017-10-04T00:00:00",
            "description": "Today's article is a short one. Not because Singular Value Decomposition (SVD) is not important, but because it is so ubiquitous that we'll touch it in other...",
            "thumbnail": "http://aiprobook.com/img/dlfp-cover.png",
            "sourceId": 8,
            "source": "Dragan.rocks Blog"
        },
        {
            "id": 9244,
            "title": "How to Use Word Embedding Layers for Deep Learning with Keras",
            "url": "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Natural Language Processing",
            "publishedOn": "2017-10-04T00:00:00",
            "description": "Word embeddings provide a dense representation of words and their relative meanings. They are an\u00a0improvement over sparse representations used in simpler bag of word model representations. Word embeddings can be learned from text data and reused among projects. They can also be learned as part of fitting a neural network on text data. In this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/10/How-to-Use-Word-Embedding-Layers-for-Deep-Learning-with-Keras.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 5691,
            "title": "Bollinger Bands and their use in Stock Market Analysis (using Quandl & tidyverse in R)",
            "url": "https://www.analyticsvidhya.com/blog/2017/10/comparative-stock-market-analysis-in-r-using-quandl-tidyverse-part-i/",
            "authors": "guest_blog",
            "tags": "Data Exploration, Intermediate, Machine Learning, R, Stock Trading, Structured Data, Technique",
            "publishedOn": "2017-10-03T00:00:00",
            "description": "Article describes Bollinger bands and their applications to stock market analysis using Quandl, Tidyverse packages in R and is applied in intra day trading",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2017/10/03090537/pexels-photo-186461.jpeg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 6937,
            "title": "Why we launched DeepMind Ethics & Society",
            "url": "https://www.deepmind.com/blog/why-we-launched-deepmind-ethics-society",
            "authors": null,
            "tags": "Company",
            "publishedOn": "2017-10-03T00:00:00",
            "description": "At DeepMind, we\u2019re proud of the role we\u2019ve played in pushing forward the science of AI, and our track record of exciting breakthroughs and major publications. We believe AI can be of extraordinary benefit to the world, but only if held to the highest ethical standards. Technology is not value neutral, and technologists must take responsibility for the ethical and social impact of their work.",
            "thumbnail": "https://assets-global.website-files.com/621d30e84caf0be3291dbf1c/621d346e395c98fb65f1185c_brand__symbol_white.svg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        },
        {
            "id": 6938,
            "title": "The hippocampus as a predictive map",
            "url": "https://www.deepmind.com/blog/the-hippocampus-as-a-predictive-map",
            "authors": null,
            "tags": "Research",
            "publishedOn": "2017-10-02T00:00:00",
            "description": "Think about how you choose a route to work, where to move house, or even which move to make in a game like Go. All of these scenarios require you to estimate the likely future reward of your decision. This is tricky because the number of possible scenarios explodes as one peers farther and farther into the future. Understanding how we do this is a major research question in neuroscience, while building systems that can effectively predict rewards is a major focus in AI research.",
            "thumbnail": "https://assets-global.website-files.com/621d30e84caf0be3291dbf1c/621d346e395c98fb65f1185c_brand__symbol_white.svg",
            "sourceId": 6,
            "source": "Deepmind Blog"
        }
    ]
}