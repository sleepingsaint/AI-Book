{
    "hasNextPage": true,
    "data": [
        {
            "id": 9038,
            "title": "How to Control the Stability of Training Neural Networks With the Batch Size",
            "url": "https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-21T00:00:00",
            "description": "Neural networks are trained using gradient descent where the estimate of the error used to update the weights is calculated based on a subset of the training dataset. The number of examples from the training dataset used in the estimate of the error gradient is called the batch size and is an important hyperparameter that [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/11/Line-Plots-of-Classification-Accuracy-on-Train-and-Test-Datasets-With-Different-Batch-Sizes.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 7597,
            "title": "Soft Actor-Critic: Deep Reinforcement Learning for Robotics",
            "url": "http://ai.googleblog.com/2019/01/soft-actor-critic-deep-reinforcement.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2019-01-18T09:00:00-08:00",
            "description": null,
            "thumbnail": "https://3.bp.blogspot.com/-dpJLgcUdPBA/XEGgQyKAvYI/AAAAAAAADtA/wp3VIlc4svoKpDrjcCx1FmyQ1qxU05t9ACLcBGAs/s72-c/image2.gif",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 9039,
            "title": "How to Accelerate Learning of Deep Neural Networks With Batch Normalization",
            "url": "https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-18T00:00:00",
            "description": "Batch normalization is a technique designed to automatically standardize the inputs to a layer in a deep learning neural network. Once implemented, batch normalization has the effect of dramatically accelerating the training process of a neural network, and in some cases improves the performance of the model via a modest regularization effect. In this tutorial, [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/11/Line-Plot-Classification-Accuracy-of-MLP-with-Batch-Normalization-After-Activation-Function-on-Train-and-Test-Datasets-over-Training-Epochs.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 5504,
            "title": "27 Amazing Data Science Books Every Data Scientist Should Read",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/27-amazing-data-science-books-every-data-scientist-should-read/",
            "authors": "Pranav Dar",
            "tags": "Beginner, Books, Data Science, Interview Questions, Listicle, Machine Learning",
            "publishedOn": "2019-01-17T00:00:00",
            "description": "Data science books every data scientist should read. Here is the list of 27 best data science books for aspiring data scientists.",
            "thumbnail": "https://www.analyticsvidhya.com/wp-content/uploads/2016/10/8314929977_28fd740070_b.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9040,
            "title": "Practical Deep Learning for Coders (Review)",
            "url": "https://machinelearningmastery.com/practical-deep-learning-for-coders-review/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning",
            "publishedOn": "2019-01-17T00:00:00",
            "description": "Practical deep learning is a challenging subject in which to get started. It is often taught in a bottom-up manner, requiring that you first get familiar with linear algebra, calculus, and mathematical optimization before eventually learning the neural network techniques. This can take years, and most of the background theory will not help you to [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2019/01/Overview-of-course-Structure.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13445,
            "title": "How machine learning impacts information security",
            "url": "https://www.oreilly.com/radar/podcast/how-machine-learning-impacts-information-security/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2019-01-17T00:00:00",
            "description": "The O\u2019Reilly Data Show Podcast: Andrew Burt on the need to modernize data protection tools and strategies.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/hacker-1944688_crop-b34a76e3cab9c07c5900b706c70a12c3-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 9041,
            "title": "A Gentle Introduction to Batch Normalization for Deep Neural Networks",
            "url": "https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-16T00:00:00",
            "description": "Training deep neural networks with tens of layers is challenging as they can be sensitive to the initial random weights and configuration of the learning algorithm. One possible reason for this difficulty is the distribution of the inputs to layers deep in the network may change after each mini-batch when the weights are updated. This [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2020/02/How-to-Calibrate-Probabilities-for-Imbalanced-Classification.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13446,
            "title": "Overcoming barriers to AI adoption",
            "url": "https://www.oreilly.com/radar/overcoming-barriers-to-ai-adoption/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2019-01-16T00:00:00",
            "description": "The program for our Artificial Intelligence Conference in New York City will showcase tools, best practices, and use cases from companies leading the way in AI adoption.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/site-3823519_1920_crop-5fb0a01fc1c4d6c97dd61dbf43468d9c-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 7598,
            "title": "Looking Back at Google\u2019s Research Efforts in 2018",
            "url": "http://ai.googleblog.com/2019/01/looking-back-at-googles-research.html",
            "authors": null,
            "tags": null,
            "publishedOn": "2019-01-15T10:00:00-08:00",
            "description": null,
            "thumbnail": "https://i.ytimg.com/vi/Mz0ikfuE_z0/0.jpg",
            "sourceId": 9,
            "source": "Google AI Blog"
        },
        {
            "id": 1944,
            "title": "New method for compressing neural networks better preserves accuracy",
            "url": "https://www.amazon.science/blog/new-method-for-compressing-neural-networks-better-preserves-accuracy",
            "authors": "Anish Acharya, Rahul Goel",
            "tags": "Conversational AI / Natural-language processing",
            "publishedOn": "2019-01-15T00:00:00",
            "description": "Neural networks have been responsible for most of the top-performing AI systems of the past decade, but they tend to be big, which means they tend to be slow. That\u2019s a problem for systems like Alexa, which depend on neural networks to process spoken requests in real time.",
            "thumbnail": "https://assets.amazon.science/dims4/default/ce84994/2147483647/strip/true/crop/1200x630+0+0/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F32%2F80%2Fc230480c4f60a534bc077755bae7%2Famazon-science-og-image-squid.png",
            "sourceId": 2,
            "source": "Amazon Science Blog"
        },
        {
            "id": 13447,
            "title": "9 AI trends on our radar",
            "url": "https://www.oreilly.com/radar/9-ai-trends-on-our-radar/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2019-01-15T00:00:00",
            "description": "How new developments in automation, machine deception, hardware, and more will shape AI.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/ai-telescope-on-balcony-crop-9063c0e8adedb0d9c269a4951b6dfaeb-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 5505,
            "title": "Get Started with PyTorch \u2013 Learn How to Build Quick & Accurate Neural Networks (with 4 Case Studies!)",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/guide-pytorch-neural-networks-case-studies/",
            "authors": "Shivam5992 Bansal",
            "tags": "Classification, Computer Vision, Deep Learning, Image, Intermediate, Libraries, NLP, Programming, Python, PyTorch, Supervised, Unstructured Data",
            "publishedOn": "2019-01-14T00:00:00",
            "description": "An introduction to pytorch and pytorch build neural networks. Get started with pytorch, how it works and learn how to build a neural network.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/pytorch-logo.png",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9042,
            "title": "3 Must-Own Books for Deep Learning Practitioners",
            "url": "https://machinelearningmastery.com/books-for-deep-learning-practitioners/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-14T00:00:00",
            "description": "Developing neural networks is often referred to as a dark art. The reason for this is that being skilled at developing neural network models comes from experience. There are no reliable methods to analytically calculate how to design a \u201cgood\u201d or \u201cbest\u201d model for your specific dataset. You must draw on experience and experiment in [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Neural-Networks-for-Pattern-Recognition.jpg",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13853,
            "title": "Contextual Parameter Generation for Neural Machine Translation",
            "url": "https://blog.ml.cmu.edu/2019/01/14/contextual-parameter-generation-for-universal-neural-machine-translation/",
            "authors": null,
            "tags": "Deep learning, Machine learning, Machine translation, Natural language processing, Research",
            "publishedOn": "2019-01-14T00:00:00",
            "description": "Machine translation is the problem of translating sentences from some source language to a target language. Neural machine translation (NMT), directly models the mapping of a source language to a target language without any need for training or tuning any component of the system separately. This has",
            "thumbnail": "https://blog.ml.cmu.edu/wp-content/uploads/2018/12/0-Overview.svg",
            "sourceId": 21,
            "source": "ML@CMU Blog"
        },
        {
            "id": 1254,
            "title": "Ensure consistency in data processing code between training and inference in Amazon SageMaker",
            "url": "https://aws.amazon.com/blogs/machine-learning/ensure-consistency-in-data-processing-code-between-training-and-inference-in-amazon-sagemaker/",
            "authors": "Thomas Hughes, Urvashi Chowdhary",
            "tags": "Amazon SageMaker",
            "publishedOn": "2019-01-11T00:00:00",
            "description": "In this blog post, we\u2019ll show you how to deploy an inference pipeline consisting of pre-processing using SparkML, inferences using XGBoost, and post-processing using SparkML. For this particular example, we are using the Car Evaluation Data Set from UCI\u2019s Machine Learning Repository and training an XGBoost model to predict the condition of a car (i.e. unacceptable, acceptable, good, or very good).",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/12/21/SageMakerInferencePipelines1.png",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 1255,
            "title": "How simpleshow uses Amazon Polly to voice stories in their explainer videos",
            "url": "https://aws.amazon.com/blogs/machine-learning/how-simpleshow-uses-amazon-polly-to-voice-stories-in-their-explainer-videos/",
            "authors": "Hans-Christian Pahlig",
            "tags": "Amazon Polly, Artificial Intelligence",
            "publishedOn": "2019-01-11T00:00:00",
            "description": "More than ten years ago, simpleshow started to help their customers explain materials, ideas, and products by using three-minute animated explainer videos. These explainer videos use two hands and simple, black and white illustration to lead viewers through a story. Today, the company also provides mysimpleshow.com, a platform that allows anyone to produce high-quality explainer [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2019/01/09/simpleshow-3.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 9043,
            "title": "How to Fix the Vanishing Gradients Problem Using the ReLU",
            "url": "https://machinelearningmastery.com/how-to-fix-vanishing-gradients-using-the-rectified-linear-activation-function/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-11T00:00:00",
            "description": "The vanishing gradients problem is one example of unstable behavior that you may encounter when training a deep neural network. It describes the situation where a deep multilayer feed-forward network or a recurrent neural network is unable to propagate useful gradient information from the output end of the model back to the layers near the [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Train-and-Test-Set-Accuracy-of-Over-Training-Epochs-for-Deep-MLP-with-ReLU-with-15-Hidden-Layers.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 1256,
            "title": "Automated and continuous deployment of Amazon SageMaker models with AWS Step Functions",
            "url": "https://aws.amazon.com/blogs/machine-learning/automated-and-continuous-deployment-of-amazon-sagemaker-models-with-aws-step-functions/",
            "authors": "John Calhoun",
            "tags": "Amazon SageMaker, Application Services, Artificial Intelligence, AWS Step Functions",
            "publishedOn": "2019-01-10T00:00:00",
            "description": "Amazon SageMaker is a complete machine learning (ML) workflow service for developing, training, and deploying models, lowering the cost of building solutions, and increasing the productivity of data science teams. Amazon SageMaker comes with many predefined algorithms. You can also create your own algorithms by supplying Docker images, a training image to train your model [\u2026]",
            "thumbnail": "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/10/10/continuous-sagemaker-deployment-8.gif",
            "sourceId": 1,
            "source": "Amazon ML Blog"
        },
        {
            "id": 5506,
            "title": "Build your First Image Classification Model in just 10 Minutes!",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/build-image-classification-model-10-minutes/",
            "authors": "Pulkit Sharma",
            "tags": "Advanced, Classification, Computer Vision, Deep Learning, Image, Project, Python, Supervised, Unstructured Data",
            "publishedOn": "2019-01-10T00:00:00",
            "description": "Learn about image classification and its use cases. This article explains how to build an image classification model in python using case study.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/deep-learning-image-classification.png",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9044,
            "title": "A Gentle Introduction to the Rectified Linear Unit (ReLU)",
            "url": "https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-09T00:00:00",
            "description": "In a neural network, the activation function is responsible for transforming the summed weighted input from the node into the activation of the node or output for that input. The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13448,
            "title": "7 data trends on our radar",
            "url": "https://www.oreilly.com/radar/7-data-trends-on-our-radar/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2019-01-08T00:00:00",
            "description": "From infrastructure to tools to training, Ben Lorica looks at what\u2019s ahead for data.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/data-telescope-crop-2e3aad0d928a04a4ca3b8f625a4fac3a-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 5507,
            "title": "A Hands-On Introduction to Time Series Classification (with Python Code)",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/introduction-time-series-classification/",
            "authors": "Aishwarya Singh",
            "tags": "Beginner, Machine Learning, Python, Structured Data, Supervised, Technique, Time Series, Time Series Forecasting",
            "publishedOn": "2019-01-07T00:00:00",
            "description": "An introduction to time series classification. In this article learn about its applications and how to build time series classification models with python.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/time-series-.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9045,
            "title": "Ensemble Neural Network Model Weights in Keras (Polyak Averaging)",
            "url": "https://machinelearningmastery.com/polyak-neural-network-model-weight-ensemble/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-07T00:00:00",
            "description": "The training process of neural networks is a challenging optimization process that can often fail to converge. This can mean that the model at the end of training may not be a stable or best-performing set of weights to use as a final model. One approach to address this problem is to use an average [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Single-Model-Test-Performance-blue-dots-and-Model-Weight-Ensemble-Test-Performance-orange-line-with-a-Exponential-Decay.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 5508,
            "title": "DataHack Radio #15: Exploring the Applications & Potential of Reinforcement Learning with Xander Steenbrugge",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/datahack-radio-reinforcement-learning-xander/",
            "authors": "Pranav Dar",
            "tags": "Deep Learning, Intermediate, Podcast, Reinforcement Learning, Reinforcement Learning",
            "publishedOn": "2019-01-06T00:00:00",
            "description": "Introduction \u201cIf intelligence was a cake, supervised learning would be the icing on the cake, and reinforcement learning would be the cherry on the cake.\u201d \u2013 Yann LeCun,\u00a0Founding Father of Convolutional Nets Reinforcement learning algorithms have been knocking on the door of industrial applications in recent years. Will they finally blow the door wide open [\u2026]",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/xander-graphics-.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9046,
            "title": "Snapshot Ensemble Deep Learning Neural Network in Python",
            "url": "https://machinelearningmastery.com/snapshot-ensemble-deep-learning-neural-network/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-04T00:00:00",
            "description": "Model ensembles can achieve lower generalization error than single models but are challenging to develop with deep learning neural networks given the computational cost of training each single model. An alternative is to train multiple model snapshots during a single training run and combine their predictions to make an ensemble prediction. A limitation of this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Cosine-Annealing-Learning-Rate-Schedule.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 13449,
            "title": "In the age of AI, fundamental value resides in data",
            "url": "https://www.oreilly.com/radar/podcast/in-the-age-of-ai-fundamental-value-resides-in-data/",
            "authors": "Ben Lorica",
            "tags": null,
            "publishedOn": "2019-01-03T00:00:00",
            "description": "The O\u2019Reilly Data Show Podcast: Haoyuan Li on accelerating analytic workloads, and innovation in data and AI in China.",
            "thumbnail": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2019/06/beijing_cbd_2015_september_night_crop-42efe66eae02f620af25fa0184e62294-1.jpg",
            "sourceId": 20,
            "source": "O`Reilly AI & ML Radar Blog"
        },
        {
            "id": 5509,
            "title": "A Comprehensive Learning Path for Deep Learning in 2019",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/comprehensive-learning-path-deep-learning-2019/",
            "authors": "Pranav Dar",
            "tags": "Beginner, Computer Vision, Deep Learning, Infographics, Interview Questions, Learning Path, Python",
            "publishedOn": "2019-01-02T00:00:00",
            "description": "Interested in deep learning but don\u2019t know where to start? This article contains a learning path for deep learning to get started in 2019.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/deep-learning-preview.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 9047,
            "title": "Impact of Dataset Size on Deep Learning Model Skill And Performance Estimates",
            "url": "https://machinelearningmastery.com/impact-of-dataset-size-on-deep-learning-model-skill-and-performance-estimates/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning Performance",
            "publishedOn": "2019-01-02T00:00:00",
            "description": "Supervised learning is challenging, although the depths of this challenge are often learned then forgotten or willfully ignored. This must be the case, because dwelling too long on this challenge may result in a pessimistic outlook. In spite of the challenge, we continue to wield supervised learning algorithms and they perform well in practice. Fundamental [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2018/10/Four-Scatter-Plots-of-the-Circles-Dataset-Varied-by-the-Amount-of-Statistical-Noise.png",
            "sourceId": 14,
            "source": "Machine Learning Mastery Blog"
        },
        {
            "id": 5510,
            "title": "The Ultimate Learning Path to Become a Data Scientist and Master Machine Learning in 2019",
            "url": "https://www.analyticsvidhya.com/blog/2019/01/learning-path-data-scientist-machine-learning-2019/",
            "authors": "Pranav Dar",
            "tags": "Analytics Vidhya, Beginner, Data Science, Deep Learning, Infographics, Interview Questions, Learning Path, Machine Learning, NLP, Python, Statistics",
            "publishedOn": "2019-01-01T00:00:00",
            "description": "Complete learning path to become a data scientist in 2019. This article contains resources that will lead you down the path to be a data scientist.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2018/01/datascience-path.jpg",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        },
        {
            "id": 5511,
            "title": "The 15 Most Popular Data Science and Machine Learning Articles on Analytics Vidhya in 2018",
            "url": "https://www.analyticsvidhya.com/blog/2018/12/most-popular-articles-analytics-vidhya-2018/",
            "authors": "Pranav Dar",
            "tags": "Analytics Vidhya, Beginner, Deep Learning, Interview Questions, Listicle, Machine Learning, NLP, Resource",
            "publishedOn": "2018-12-31T00:00:00",
            "description": "List of top 12 best and most popular data and machine learning articles for aspiring data scientists that were published on Analytics Vidhya in 2018.",
            "thumbnail": "https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/analytics-2158454_960_720.png",
            "sourceId": 3,
            "source": "Analytics Vidhya Blog"
        }
    ]
}