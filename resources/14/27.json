{
    "hasNextPage": true,
    "data": [
        {
            "id": 9292,
            "title": "How to Get Reproducible Results with Keras",
            "url": "https://machinelearningmastery.com/reproducible-results-neural-networks-keras/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning",
            "publishedOn": "2017-06-14T00:00:00",
            "description": "Neural network algorithms are stochastic. This means they make use of randomness, such as initializing to random weights, and in turn the same network trained on the same data can produce different results. This can be confusing to beginners as the algorithm appears unstable, and in fact they are by design. The random initialization allows [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/How-to-Get-Reproducible-Results-from-Neural-Networks-with-Keras.jpg"
        },
        {
            "id": 9293,
            "title": "How to use an Encoder-Decoder LSTM to Echo Sequences of Random Integers",
            "url": "https://machinelearningmastery.com/how-to-use-an-encoder-decoder-lstm-to-echo-sequences-of-random-integers/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-06-12T00:00:00",
            "description": "A powerful feature of Long Short-Term Memory (LSTM) recurrent neural networks is that they can remember observations over long sequence intervals. This can be demonstrated by contriving a simple sequence echo problem where the entire input sequence or partial contiguous blocks of the input sequence are echoed as an output sequence. Developing LSTM recurrent neural [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/How-to-use-an-Encoder-Decoder-LSTM-to-Echo-Sequences-of-Random-Integers.jpg"
        },
        {
            "id": 9294,
            "title": "How to Learn to Echo Random Integers with LSTMs in Keras",
            "url": "https://machinelearningmastery.com/learn-echo-random-integers-long-short-term-memory-recurrent-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-06-09T00:00:00",
            "description": "Long Short-Term Memory (LSTM) Recurrent Neural Networks are able to learn the order dependence in long sequence data. They are a fundamental technique used in a range of state-of-the-art results, such as image captioning and machine translation. They can also be difficult to understand, specifically how to frame a problem to get the most out [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/How-to-Learn-to-Echo-Random-Integers-with-Long-Short-Term-Memory-Recurrent-Neural-Networks.jpg"
        },
        {
            "id": 9295,
            "title": "The 5 Step Life-Cycle for Long Short-Term Memory Models in Keras",
            "url": "https://machinelearningmastery.com/5-step-life-cycle-long-short-term-memory-models-keras/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-06-07T00:00:00",
            "description": "Deep learning neural networks are very easy to create and evaluate in Python with Keras, but you must follow a strict model life-cycle. In this post, you will discover the step-by-step life-cycle for creating, training, and evaluating Long Short-Term Memory (LSTM) Recurrent Neural Networks in Keras and how to make predictions with a trained model. [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/The-5-Step-Life-Cycle-for-Long-Short-Term-Memory-Models-in-Keras.jpg"
        },
        {
            "id": 9296,
            "title": "How to Calculate Bootstrap Confidence Intervals For Machine Learning Results in Python",
            "url": "https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/",
            "authors": "Jason Brownlee",
            "tags": "Statistics",
            "publishedOn": "2017-06-05T00:00:00",
            "description": "It is important to both present the expected skill of a machine learning model a well as confidence intervals for that model skill. Confidence intervals provide a range of model skills and a likelihood that the model skill will fall between the ranges when making predictions on new data. For example, a 95% likelihood of [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/How-to-Calculate-Bootstrap-Confidence-Intervals-For-Machine-Learning-Results-in-Python.jpg"
        },
        {
            "id": 9297,
            "title": "How to Report Classifier Performance with Confidence Intervals",
            "url": "https://machinelearningmastery.com/report-classifier-performance-confidence-intervals/",
            "authors": "Jason Brownlee",
            "tags": "Statistics",
            "publishedOn": "2017-06-02T00:00:00",
            "description": "Once you choose a machine learning algorithm for your classification problem, you need to report the performance of the model to stakeholders. This is important so that you can set the expectations for the model on new data. A common mistake is to report the classification accuracy of the model alone. In this post, you [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/06/How-to-Report-Classifier-Performance-with-Confidence-Intervals.jpg"
        },
        {
            "id": 9298,
            "title": "How to Evaluate the Skill of Deep Learning Models",
            "url": "https://machinelearningmastery.com/evaluate-skill-deep-learning-models/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning",
            "publishedOn": "2017-05-31T00:00:00",
            "description": "I often see practitioners expressing confusion about how to evaluate a deep learning model. This is often obvious from questions like: What random seed should I use? Do I need a random seed? Why don\u2019t I get the same results on subsequent runs? In this post, you will discover the procedure that you can use [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-Evaluate-the-Skill-of-Deep-Learning-Models.jpg"
        },
        {
            "id": 9299,
            "title": "7 Ways to Handle Large Data Files for Machine Learning",
            "url": "https://machinelearningmastery.com/large-data-files-machine-learning/",
            "authors": "Jason Brownlee",
            "tags": "Machine Learning Process",
            "publishedOn": "2017-05-29T00:00:00",
            "description": "Exploring and applying machine learning algorithms to datasets that are too large to fit into memory is pretty common. This leads to questions like: How do I load my multiple gigabyte data file? Algorithms crash when I try to run my dataset; what should I do? Can you help me with out-of-memory errors? In this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/7-Ways-to-Handle-Large-Data-Files-for-Machine-Learning.jpg"
        },
        {
            "id": 9300,
            "title": "On the Suitability of Long Short-Term Memory Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/suitability-long-short-term-memory-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-05-26T00:00:00",
            "description": "Long Short-Term Memory (LSTM) is a type of recurrent neural network that can learn the order dependence between items in a sequence. LSTMs have the promise of being able to learn the context required to make predictions in time series forecasting problems, rather than having this context pre-specified and fixed. Given the promise, there is [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/On-the-Suitability-of-Long-Short-Term-Memory-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9301,
            "title": "A Gentle Introduction to Long Short-Term Memory Networks by the Experts",
            "url": "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-05-24T00:00:00",
            "description": "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more. LSTMs are a complex area of deep learning. It can be hard to get your hands around what [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/A-Gentle-Introduction-to-Long-Short-Term-Memory-Networks-by-the-Experts.jpg"
        },
        {
            "id": 9302,
            "title": "The Promise of Recurrent Neural Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/promise-recurrent-neural-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-05-22T00:00:00",
            "description": "Recurrent neural networks are a type of neural network that add the explicit handling of order in input observations. This capability suggests that the promise of recurrent neural networks is to learn the temporal context of input sequences in order to make better predictions. That is, that the suite of lagged observations required to make [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/The-Promise-of-Recurrent-Neural-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9303,
            "title": "Learn to Add Numbers with an Encoder-Decoder LSTM Recurrent Neural Network",
            "url": "https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-05-19T00:00:00",
            "description": "Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Network (RNN) that are capable of learning the relationships between elements in an input sequence. A good demonstration of LSTMs is to learn how to combine multiple terms together using a mathematical operation like a sum and outputting the result of the calculation. A [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-Learn-to-Add-Numbers-with-seq2seq-Recurrent-Neural-Networks.jpg"
        },
        {
            "id": 9304,
            "title": "How to Use the TimeDistributed Layer in Keras",
            "url": "https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-05-17T00:00:00",
            "description": "Long Short-Term Networks or LSTMs are a popular and powerful type of Recurrent Neural Network, or RNN. They can be quite difficult to configure and apply to arbitrary sequence prediction problems, even with well defined and \u201ceasy to use\u201d interfaces like those provided in the Keras deep learning library in Python. One reason for this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-Use-the-TimeDistributed-Layer-for-Long-Short-Term-Memory-Networks-in-Python.jpg"
        },
        {
            "id": 9305,
            "title": "How to use Different Batch Sizes when Training and Predicting with LSTMs",
            "url": "https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-05-15T00:00:00",
            "description": "Keras uses fast symbolic mathematical libraries as a backend, such as TensorFlow and Theano. A downside of using these libraries is that the shape and size of your data must be defined once up front and held constant regardless of whether you are training your network or making predictions. On sequence prediction problems, it may [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-use-Different-Batch-Sizes-for-Training-and-Predicting-in-Python-with-Keras.jpg"
        },
        {
            "id": 9306,
            "title": "Demonstration of Memory with a Long Short-Term Memory Network in Python",
            "url": "https://machinelearningmastery.com/memory-in-a-long-short-term-memory-network/",
            "authors": "Jason Brownlee",
            "tags": "Long Short-Term Memory Networks",
            "publishedOn": "2017-05-12T00:00:00",
            "description": "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning over long sequences. This differentiates them from regular multilayer neural networks that do not have memory and can only learn a mapping between input and output patterns. It is important to understand the capabilities of complex neural networks like LSTMs [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/A-Demonstration-of-Memory-in-a-Long-Short-Term-Memory-Network.jpg"
        },
        {
            "id": 9307,
            "title": "Multistep Time Series Forecasting with LSTMs in Python",
            "url": "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-05-10T00:00:00",
            "description": "The Long Short-Term Memory network or LSTM is a recurrent neural network that can learn and forecast long sequences. A benefit of LSTMs in addition to learning long sequences is that they can learn to make a one-shot multi-step forecast which may be useful for time series forecasting. A difficulty with LSTMs is that they [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/Line-Plot-of-Shampoo-Sales-Dataset-with-Multi-Step-LSTM-Forecasts.png"
        },
        {
            "id": 9308,
            "title": "How to Convert a Time Series to a Supervised Learning Problem in Python",
            "url": "https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/",
            "authors": "Jason Brownlee",
            "tags": "Time Series",
            "publishedOn": "2017-05-08T00:00:00",
            "description": "Machine learning methods like deep learning can be used for time series forecasting. Before machine learning can be used, time series forecasting problems must be re-framed as supervised learning problems. From a sequence to pairs of input and output sequences. In this tutorial, you will discover how to transform univariate and multivariate time series forecasting [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-Convert-a-Time-Series-to-a-Supervised-Learning-Problem-in-Python.jpg"
        },
        {
            "id": 9309,
            "title": "Weight Regularization with LSTM Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/use-weight-regularization-lstm-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-05-05T00:00:00",
            "description": "Long Short-Term Memory (LSTM) models are a recurrent neural network capable of learning sequences of observations. This may make them a network well suited to time series forecasting. An issue with LSTMs is that they can easily overfit training data, reducing their predictive skill. Weight regularization is a technique for imposing constraints (such as L1 [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/How-to-Use-Weight-Regularization-with-LSTM-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9310,
            "title": "How to Use Statistical Significance Tests to Interpret Machine Learning Results",
            "url": "https://machinelearningmastery.com/use-statistical-significance-tests-interpret-machine-learning-results/",
            "authors": "Jason Brownlee",
            "tags": "Statistics",
            "publishedOn": "2017-05-03T00:00:00",
            "description": "It is good practice to gather a population of results when comparing two different machine learning algorithms or when comparing the same algorithm with different configurations. Repeating each experimental run 30 or more times gives you a population of results from which you can calculate the mean expected performance, given the stochastic nature of most [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/05/How-to-Use-Statistical-Significance-Tests-to-Interpret-Machine-Learning-Results.jpg"
        },
        {
            "id": 9311,
            "title": "Estimate the Number of Experiment Repeats for Stochastic Machine Learning Algorithms",
            "url": "https://machinelearningmastery.com/estimate-number-experiment-repeats-stochastic-machine-learning-algorithms/",
            "authors": "Jason Brownlee",
            "tags": "Statistics",
            "publishedOn": "2017-05-01T00:00:00",
            "description": "A problem with many stochastic machine learning algorithms is that different runs of the same algorithm on the same data return different results. This means that when performing experiments to configure a stochastic algorithm or compare algorithms, you must collect multiple results and use the average performance to summarize the skill of the model. This [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/Zoomed-Line-Plot-of-Mean-Result-with-Standard-Error-Bars-and-Population-Mean.png"
        },
        {
            "id": 9312,
            "title": "Dropout with LSTM Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/use-dropout-lstm-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-28T00:00:00",
            "description": "Long Short-Term Memory (LSTM) models are a type of recurrent neural network capable of learning sequences of observations. This may make them a network well suited to time series forecasting. An issue with LSTMs is that they can easily overfit training data, reducing their predictive skill. Dropout is a regularization method where input and recurrent [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/How-to-Use-Dropout-with-LSTM-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9313,
            "title": "How to Configure Multilayer Perceptron Network for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/exploratory-configuration-multilayer-perceptron-network-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-26T00:00:00",
            "description": "It can be difficult when starting out on a new predictive modeling project with neural networks. There is so much to configure, and no clear idea where to start. It is important to be systematic. You can break bad assumptions and quickly hone in on configurations that work and areas for further investigation likely to [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/Exploratory-Configuration-of-a-Multilayer-Perceptron-Network-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9314,
            "title": "Instability of Online Learning for Stateful LSTM for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/instability-online-learning-stateful-lstm-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-24T00:00:00",
            "description": "Some neural network configurations can result in an unstable model. This can make them hard to characterize and compare to other model configurations on the same problem using descriptive statistics. One good example of a seemingly unstable model is the use of online learning (a batch size of 1) for a stateful Long Short-Term Memory [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/Instability-of-Online-Learning-for-Stateful-LSTM-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9315,
            "title": "Stateful and Stateless LSTM for Time Series Forecasting with Python",
            "url": "https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-21T00:00:00",
            "description": "The Keras Python deep learning library supports both stateful and stateless Long Short-Term Memory (LSTM) networks. When using stateful LSTM networks, we have fine-grained control over when the internal state of the LSTM network is reset. Therefore, it is important to understand different ways of managing this internal state when fitting and making predictions with [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/Stateful-and-Stateless-LSTM-for-Time-Series-Forecasting-with-Python.jpg"
        },
        {
            "id": 9316,
            "title": "How to Use Features in LSTM Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/use-features-lstm-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-19T00:00:00",
            "description": "The Long Short-Term Memory (LSTM) network in Keras supports multiple input features. This raises the question as to whether lag observations for a univariate time series can be used as features for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as features [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/How-to-Use-Features-in-LSTM-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9317,
            "title": "How to Use Timesteps in LSTM Networks for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/use-timesteps-lstm-networks-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-17T00:00:00",
            "description": "The Long Short-Term Memory (LSTM) network in Keras supports time steps. This raises the question as to whether lag observations for a univariate time series can be used as time steps for an LSTM and whether or not this improves forecast performance. In this tutorial, we will investigate the use of lag observations as time [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/How-to-Use-Timesteps-in-LSTM-Networks-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9318,
            "title": "How to Update LSTM Networks During Training for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/update-lstm-networks-training-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-14T00:00:00",
            "description": "A benefit of using neural network models for time series forecasting is that the weights can be updated as new data becomes available. In this tutorial, you will discover how you can update a Long Short-Term Memory (LSTM) recurrent neural network with new data for time series forecasting. After completing this tutorial, you will know: [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/How-to-Update-LSTM-Networks-During-Training-for-Time-Series-Forecasting.jpg"
        },
        {
            "id": 9319,
            "title": "How to Tune LSTM Hyperparameters with Keras for Time Series Forecasting",
            "url": "https://machinelearningmastery.com/tune-lstm-hyperparameters-keras-time-series-forecasting/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-12T00:00:00",
            "description": "Configuring neural networks is difficult because there is no good theory on how to do it. You must be systematic and explore different configurations both from a dynamical and an objective results point of a view to try to understand what is going on for a given predictive modeling problem. In this tutorial, you will [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/Diagnostic-Results-with-500-Epochs.png"
        },
        {
            "id": 9320,
            "title": "How to Seed State for LSTMs for Time Series Forecasting in Python",
            "url": "https://machinelearningmastery.com/seed-state-lstms-time-series-forecasting-python/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-10T00:00:00",
            "description": "Long Short-Term Memory networks, or LSTMs, are a powerful type of recurrent neural network capable of learning long sequences of observations. A promise of LSTMs is that they may be effective at time series forecasting, although the method is known to be difficult to configure and use for these purposes. A key feature of LSTMs [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/03/How-to-Seed-State-for-LSTMs-for-Time-Series-Forecasting-in-Python.jpg"
        },
        {
            "id": 9321,
            "title": "Time Series Forecasting with the Long Short-Term Memory Network in Python",
            "url": "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/",
            "authors": "Jason Brownlee",
            "tags": "Deep Learning for Time Series",
            "publishedOn": "2017-04-07T00:00:00",
            "description": "The Long Short-Term Memory recurrent neural network has the promise of learning long sequences of observations. It seems a perfect match for time series forecasting, and in fact, it may be. In this tutorial, you will discover how to develop an LSTM forecast model for a one-step univariate time series forecasting problem. After completing this [\u2026]",
            "thumbnail": "https://machinelearningmastery.com/wp-content/uploads/2017/04/Time-Series-Forecasting-with-the-Long-Short-Term-Memory-Network-in-Python.jpg"
        }
    ]
}